{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea0118b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running mode: median\n",
      "[median] Target: 1788 keypoints, desc shape: (1788, 61)\n",
      "Candidate: Charmender.png | kp:56 | good:81 | inliers:18\n",
      "Candidate: Gastly.png | kp:942 | good:41 | inliers:8\n",
      "Candidate: Piplup.png | kp:230 | good:51 | inliers:14\n",
      "Candidate: Quaxly.png | kp:149 | good:72 | inliers:17\n",
      "Candidate: Rowlet.png | kp:1608 | good:26 | inliers:5\n",
      "Candidate: Squirtle.png | kp:1363 | good:26 | inliers:0\n",
      "Candidate: Treecko.png | kp:281 | good:91 | inliers:12\n",
      "--- Top candidates for mode: median\n",
      "Rank 1: Charmender.png | kp:56 | good:81 | inliers:18\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\features2d\\src\\draw.cpp:228: error: (-201:Incorrect size of input array) matchesMask must have the same size as matches1to2 in function 'cv::drawMatches'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 166\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m SHOW_PLOTS:\n\u001b[0;32m    165\u001b[0m             title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Rank \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (good=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgood_matches_after_lowe\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, inliers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minlier_count_ransac\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 166\u001b[0m             \u001b[43mdraw_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp_tgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     all_mode_results[mode] \u001b[38;5;241m=\u001b[39m res_sorted\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# Summary comparison between modes for top-1\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 103\u001b[0m, in \u001b[0;36mdraw_matches\u001b[1;34m(img1_color, img2_color, kp1, kp2, matches, mask, max_display, title)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Draw matched keypoints, optionally mask (inliers).\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m draw_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(matchColor \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    100\u001b[0m                    singlePointColor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    101\u001b[0m                    matchesMask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m    102\u001b[0m                    flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m img_matches \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrawMatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_display\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdraw_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m title:\n\u001b[0;32m    105\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m)); plt\u001b[38;5;241m.\u001b[39mtitle(title)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\features2d\\src\\draw.cpp:228: error: (-201:Incorrect size of input array) matchesMask must have the same size as matches1to2 in function 'cv::drawMatches'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Config / Hyperparams ----------\n",
    "DATA_FOLDER = \"./Images/Data\"   # ganti dengan folder berisi kandidat object\n",
    "TARGET_PATH = \"./Images/Object.png\"     # ganti dengan path gambar target\n",
    "SHOW_PLOTS = True\n",
    "\n",
    "# Preprocessing choices: 'median' or 'gaussian'\n",
    "PREPROCESS_MODES = [\"median\", \"gaussian\"]  # kita akan jalankan keduanya\n",
    "\n",
    "# AKAZE params (menggunakan default)\n",
    "AKAZE_THRESHOLD = None  # gunakan default AKAZE\n",
    "\n",
    "# FLANN LSH params untuk descriptor biner (AKAZE menghasilkan binary-like descriptors)\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = dict(algorithm = FLANN_INDEX_LSH,\n",
    "                    table_number = 12, # 12..20 typical\n",
    "                    key_size = 20,     # 12..20\n",
    "                    multi_probe_level = 2)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "# Lowe ratio\n",
    "LOWE_RATIO = 0.75\n",
    "\n",
    "# Minimum good matches (after Lowe) to attempt homography\n",
    "MIN_GOOD_MATCHES = 10\n",
    "\n",
    "# RANSAC threshold (pixel)\n",
    "RANSAC_REPROJ_THRESHOLD = 4.0\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def preprocess(img_gray, mode=\"median\"):\n",
    "    \"\"\"Preprocess grayscale image: histogram equalization + blur (median or gaussian).\"\"\"\n",
    "    # histogram equalization (works with single channel)\n",
    "    img_eq = cv2.equalizeHist(img_gray)\n",
    "    if mode == \"median\":\n",
    "        # kernel size 5 as di-deskripsikan\n",
    "        img_blur = cv2.medianBlur(img_eq, 5)\n",
    "    elif mode == \"gaussian\":\n",
    "        # kernel (3,3), sigmaX=0 as di-deskripsikan\n",
    "        img_blur = cv2.GaussianBlur(img_eq, (3,3), 0)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown preprocess mode\")\n",
    "    return img_blur\n",
    "\n",
    "def detect_and_describe(img_gray, detector=None):\n",
    "    \"\"\"Return keypoints and descriptors using AKAZE.\"\"\"\n",
    "    if detector is None:\n",
    "        detector = cv2.AKAZE_create()\n",
    "    kps, desc = detector.detectAndCompute(img_gray, None)\n",
    "    return kps, desc\n",
    "\n",
    "def flann_match(desc1, desc2):\n",
    "    \"\"\"FLANN-based knnMatch (k=2) for binary descriptors using LSH index.\"\"\"\n",
    "    if desc1 is None or desc2 is None:\n",
    "        return []\n",
    "    # Ensure dtype is uint8 for binary descriptors (AKAZE often returns uint8)\n",
    "    # OpenCV FLANN expects descriptors to be of type float32 for some algorithms; \n",
    "    # but for LSH it works with uint8. If errors occur, convert to np.uint8.\n",
    "    if desc1.dtype != np.uint8:\n",
    "        desc1 = desc1.astype(np.uint8)\n",
    "    if desc2.dtype != np.uint8:\n",
    "        desc2 = desc2.astype(np.uint8)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    # do knn match k=2\n",
    "    matches = flann.knnMatch(desc1, desc2, k=2)\n",
    "    return matches\n",
    "\n",
    "def lowe_ratio_filter(knn_matches, ratio=0.75):\n",
    "    \"\"\"Apply Lowe's ratio test to knn matches (list of [m,n])\"\"\"\n",
    "    good = []\n",
    "    for m_n in knn_matches:\n",
    "        if len(m_n) != 2:\n",
    "            continue\n",
    "        m, n = m_n\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good.append(m)\n",
    "    return good\n",
    "\n",
    "def ransac_filter(kp1, kp2, good_matches, ransac_thresh=4.0):\n",
    "    \"\"\"Estimate homography and return inlier mask and inlier matches count.\"\"\"\n",
    "    if len(good_matches) < MIN_GOOD_MATCHES:\n",
    "        return None, None, 0\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, ransac_thresh)\n",
    "    if mask is None:\n",
    "        return M, None, 0\n",
    "    inliers = mask.ravel().tolist()\n",
    "    inlier_count = int(np.sum(mask))\n",
    "    return M, mask, inlier_count\n",
    "\n",
    "def draw_matches(img1_color, img2_color, kp1, kp2, matches, mask=None, max_display=50, title=None):\n",
    "    \"\"\"Draw matched keypoints, optionally mask (inliers).\"\"\"\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                       singlePointColor = None,\n",
    "                       matchesMask = None if mask is None else mask.ravel().tolist(),\n",
    "                       flags = 2)\n",
    "    img_matches = cv2.drawMatches(img1_color, kp1, img2_color, kp2, matches[:max_display], None, **draw_params)\n",
    "    if title:\n",
    "        plt.figure(figsize=(12,6)); plt.title(title)\n",
    "    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ---------- Main pipeline ----------\n",
    "def evaluate_folder(target_path, folder_path, preprocess_mode=\"median\", show_each=True):\n",
    "    # load target\n",
    "    tgt_color = cv2.imread(target_path)\n",
    "    if tgt_color is None:\n",
    "        raise FileNotFoundError(f\"Target image not found: {target_path}\")\n",
    "    tgt_gray = cv2.cvtColor(tgt_color, cv2.COLOR_BGR2GRAY)\n",
    "    tgt_prep = preprocess(tgt_gray, mode=preprocess_mode)\n",
    "    kp_tgt, desc_tgt = detect_and_describe(tgt_prep)\n",
    "    print(f\"[{preprocess_mode}] Target: {len(kp_tgt)} keypoints, desc shape: {None if desc_tgt is None else desc_tgt.shape}\")\n",
    "\n",
    "    results = []\n",
    "    # iterate candidates\n",
    "    image_files = sorted(glob(os.path.join(folder_path, \"*.*\")))\n",
    "    for img_path in image_files:\n",
    "        img_color = cv2.imread(img_path)\n",
    "        if img_color is None:\n",
    "            continue\n",
    "        img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "        img_prep = preprocess(img_gray, mode=preprocess_mode)\n",
    "        kp_img, desc_img = detect_and_describe(img_prep)\n",
    "        # FLANN knn\n",
    "        knn = flann_match(desc_tgt, desc_img)\n",
    "        good = lowe_ratio_filter(knn, ratio=LOWE_RATIO)\n",
    "        M, mask, inlier_count = (None, None, 0)\n",
    "        if len(good) >= MIN_GOOD_MATCHES:\n",
    "            M, mask, inlier_count = ransac_filter(kp_tgt, kp_img, good, ransac_thresh=RANSAC_REPROJ_THRESHOLD)\n",
    "        # store metrics\n",
    "        metrics = {\n",
    "            \"path\": img_path,\n",
    "            \"num_kp\": len(kp_img),\n",
    "            \"desc_shape\": None if desc_img is None else desc_img.shape,\n",
    "            \"knn_total_pairs\": len(knn),\n",
    "            \"good_matches_after_lowe\": len(good),\n",
    "            \"inlier_count_ransac\": inlier_count,\n",
    "            \"kp_tgt\": len(kp_tgt)\n",
    "        }\n",
    "        results.append((metrics, img_color, kp_img, good, mask))\n",
    "        if show_each:\n",
    "            print(f\"Candidate: {os.path.basename(img_path)} | kp:{metrics['num_kp']} | good:{metrics['good_matches_after_lowe']} | inliers:{metrics['inlier_count_ransac']}\")\n",
    "    # choose best by inlier_count (primary), then by good_matches\n",
    "    results_sorted = sorted(results, key=lambda x: (x[0]['inlier_count_ransac'], x[0]['good_matches_after_lowe']), reverse=True)\n",
    "    return results_sorted, tgt_color, kp_tgt, tgt_prep\n",
    "\n",
    "# ---------- Run ----------\n",
    "if __name__ == \"__main__\":\n",
    "    all_mode_results = {}\n",
    "    for mode in PREPROCESS_MODES:\n",
    "        print(\"=== Running mode:\", mode)\n",
    "        res_sorted, tgt_color, kp_tgt, tgt_prep = evaluate_folder(TARGET_PATH, DATA_FOLDER, preprocess_mode=mode, show_each=True)\n",
    "        # print top 3\n",
    "        print(\"--- Top candidates for mode:\", mode)\n",
    "        for i, (metrics, img_color, kp_img, good, mask) in enumerate(res_sorted[:3]):\n",
    "            print(f\"Rank {i+1}: {os.path.basename(metrics['path'])} | kp:{metrics['num_kp']} | good:{metrics['good_matches_after_lowe']} | inliers:{metrics['inlier_count_ransac']}\")\n",
    "            if SHOW_PLOTS:\n",
    "                title = f\"Mode={mode} | Rank {i+1}: {os.path.basename(metrics['path'])} (good={metrics['good_matches_after_lowe']}, inliers={metrics['inlier_count_ransac']})\"\n",
    "                draw_matches(tgt_color, img_color, kp_tgt, kp_img, good, mask=mask, title=title)\n",
    "        all_mode_results[mode] = res_sorted\n",
    "\n",
    "    # Summary comparison between modes for top-1\n",
    "    print(\"\\n=== Summary comparison (top-1 each mode) ===\")\n",
    "    for mode, res_sorted in all_mode_results.items():\n",
    "        if len(res_sorted) == 0:\n",
    "            print(mode, \"no candidates found\")\n",
    "            continue\n",
    "        metrics = res_sorted[0][0]\n",
    "        print(mode, \"->\", os.path.basename(metrics['path']), \"| good:\", metrics['good_matches_after_lowe'], \"| inliers:\", metrics['inlier_count_ransac'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
